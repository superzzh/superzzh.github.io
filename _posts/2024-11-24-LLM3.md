## 大模型的商业化落地挑战

更好地控制大模型生成：

- 生成
    - 优点：内容的多样性、创造性
    - 缺点：存在不可控制的问题
- 检索
    - 优点：可控
    - 缺点：内容具有局限性

结合两者：检索增强生成(Retrieval-augmented Generation, RAG)

## 案例：金融智能客服系统的几种思路

1. 专家系统
2. 生成式模型
3. 大模型检索增强

![](/images/大模型应用课程/Lesson4/system.jpg)

## 基于文档的LLM回复系统搭建框架

![](/images/大模型应用课程/Lesson4/rag.jpg)

目前，RAG不能完全解决hallucination（幻觉，一个很fancy但是逼气很重的名词）问题：
- 检索准确率受限
- LLM理解能力有限
- 问题的复杂度
- 错位在以上步骤中累积

## 实践

### 把文本切分成Trunks

- 根据句子来切分
- 按照字符数来切分
- 按固定字符数，但结合`overlapping window`
- 递归方法：`RecursiveCharacterTextSplitter`
- 根据语义来分割

#### Split by Sentence


```python
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize

text = ("The Earth's atmosphere is composed of layers, including the troposphere, "
        "stratosphere, mesosphere, thermosphere, and exosphere. The troposphere is "
        "the lowest layer where all weather takes place and contains 75% of the atmosphere's mass. "
        "Above this, the stratosphere contains the ozone layer, which protects the Earth "
        "from harmful ultraviolet radiation.")

# Split the text into sentences
chunks = sent_tokenize(text)

for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

#### Fixed_length_chunks


```python
def fixed_length_chunks(text, chunk_size):
    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]

chunks = fixed_length_chunks(text, 100)  # 假设我们想要100个字符的块

for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

#### Chunks with overlapping window


```python
def sliding_window_chunks(text, chunk_size, stride):
    return [text[i:i+chunk_size] for i in range(0, len(text), stride)]

chunks = sliding_window_chunks(text, 100, 50)  # 100个字符的块，步长为50

for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

#### RecursiveCharacterTextSplitter from langchain


```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text = '''The Earth's atmosphere is a layer of gases surrounding the planet Earth and retained by Earth's gravity. 
It contains roughly 78% nitrogen and 21% oxygen, with trace amounts of other gases. 
The atmosphere protects life on Earth by absorbing ultraviolet solar radiation and reducing temperature extremes between day and night.
'''

splitter = RecursiveCharacterTextSplitter(
    chunk_size = 150,
    chunk_overlap = 20,
    length_function = len,
)
trunks = splitter.split_text(text)
for i, chunk in enumerate(trunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

#### 中文情形


```python
 %pip install jieba
```

    Requirement already satisfied: jieba in /Users/wenzheli/opt/anaconda3/lib/python3.9/site-packages (0.42.1)
    Note: you may need to restart the kernel to use updated packages.
    


```python
# 按照sentence来切分
import re

text = "在这里，我们有一段超过200字的中文文本作为输入例子。这段文本是关于自然语言处理的简介。自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言。在这一领域中，机器学习技术扮演着核心角色。通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言。这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面。随着深度学习技术的发展，自然语言处理的准确性和效率都得到了显著提升。当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等。自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性和智能化水平也具有重要意义。"
# 正则表达式匹配中文句子结束的标点符号
sentences = re.split(r'(。|？|！|\…\…)', text)
# 重新组合句子和结尾的标点符号
chunks = [sentence + (punctuation if punctuation else '') for sentence, punctuation in zip(sentences[::2], sentences[1::2])]
for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

    块 1: 27: 在这里，我们有一段超过200字的中文文本作为输入例子。
    块 2: 17: 这段文本是关于自然语言处理的简介。
    块 3: 51: 自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言。
    块 4: 21: 在这一领域中，机器学习技术扮演着核心角色。
    块 5: 34: 通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言。
    块 6: 35: 这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面。
    块 7: 34: 随着深度学习技术的发展，自然语言处理的准确性和效率都得到了显著提升。
    块 8: 47: 当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等。
    块 9: 47: 自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性和智能化水平也具有重要意义。
    


```python
# 按照固定字符数切分
def split_by_fixed_char_count(text, count):
    return [text[i:i+count] for i in range(0, len(text), count)]

# 假设我们按照每100个字符来切分文本
chunks = split_by_fixed_char_count(text, 100)
for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

    块 1: 100: 在这里，我们有一段超过200字的中文文本作为输入例子。这段文本是关于自然语言处理的简介。自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言。在这一领域
    块 2: 100: 中，机器学习技术扮演着核心角色。通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言。这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面。随着深度学习技术的发展，自然语
    块 3: 100: 言处理的准确性和效率都得到了显著提升。当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等。自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性和
    块 4: 13: 智能化水平也具有重要意义。
    


```python
# 按照固定sentence数切分

def split_by_fixed_sentence_count(sentences, count):
    return [sentences[i:i+count] for i in range(0, len(sentences), count)]

# 假设我们按照每5个句子来切分文本
chunks = split_by_fixed_sentence_count(sentences, 5)

for i, chunk in enumerate(chunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

    块 1: 5: ['在这里，我们有一段超过200字的中文文本作为输入例子', '。', '这段文本是关于自然语言处理的简介', '。', '自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言']
    块 2: 5: ['。', '在这一领域中，机器学习技术扮演着核心角色', '。', '通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言', '。']
    块 3: 5: ['这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面', '。', '随着深度学习技术的发展，自然语言处理的准确性和效率都得到了显著提升', '。', '当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等']
    块 4: 4: ['。', '自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性和智能化水平也具有重要意义', '。', '']
    


```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text = """
在这里，我们有一段超过200字的中文文本作为输入例子。这段文本是关于自然语言处理的简介。
自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言。
在这一领域中，机器学习技术扮演着核心角色。通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言。
这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面。随着深度学习技术的发展，自然语言处理的准确性和效率都得到了显著提升。
当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等。自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性和智能化水平也具有重要意义。
"""

splitter = RecursiveCharacterTextSplitter(
    chunk_size = 150,
    chunk_overlap = 0,
    length_function = len,
)

trunks = splitter.split_text(text)
for i, chunk in enumerate(trunks):
    print(f"块 {i+1}: {len(chunk)}: {chunk}")
```

    块 1: 149: 在这里，我们有一段超过200字的中文文本作为输入例子。这段文本是关于自然语言处理的简介。自然语言处理（NLP）是计算机科学、人工智能和语言学的交叉领域，它旨在让计算机能够理解和处理人类语言。在这一领域中，机器学习技术扮演着核心角色。通过使用各种算法，计算机可以解析、理解、甚至生成人类可以理解的语言
    块 2: 150: 。这一技术已广泛应用于机器翻译、情感分析、自动摘要、实体识别等多个方面。随着深度学习技术的发展，自然语言处理的准确性和效率都得到了显著提升。当前，一些高级的NLP系统已经能够完成复杂的语言理解任务，例如问答系统、语音识别和对话系统等。自然语言处理的研究不仅有助于改善人机交互，而且对于提高机器的自主性
    块 3: 14: 和智能化水平也具有重要意义。
    

### 文本相似度计算

```python
def get_embedding(text, model="text-embedding-ada-002"):
   text = text.replace("\n", " ")
   return client.embeddings.create(input = [text], model=model).data[0].embedding
```


```python
import numpy as np

def cosine_similarity(A, B):
    dot_product = np.dot(A, B)
    norm_A = np.linalg.norm(A)
    norm_B = np.linalg.norm(B)
    return dot_product / (norm_A * norm_B)
```


```python
emb1 = get_embedding("大模型的应用场景很多")
emb2 = get_embedding("大模型")
emb3 = get_embedding("大模型有很多应用场景")
emb4 = get_embedding("Java开发")
```


```python
cosine_similarity(emb1, emb2)
```




    0.9227828346114963




```python
cosine_similarity(emb1, emb4)
```




    0.796131924008725


