---
title: LLM Lesson2
date: 2024-07-01 12:50:00 +0800 #时间， 最后为时区北京 +0800
categories: [大语言模型工程师实训营] #上级文文档，下级文档
tags: [大模型]     # TAG
author: 陈健chenjian
---

# 大模型的使用与微调方法——Qwen与LoRA

## 一、为什么要使用和微调开源大模型？

- 调用ChatGPT的问题（成本、稳定性）
- 预训练大模型的缺陷（幻觉、价值观）
- 领域适配（准确率）
    - 特定问题特定回答
- 企业级数据（隐私性）

## 二、如何部署开源大模型

- 接口API形式
- Web形式
- 开源大模型社区

## 三、如何微调开源大模型

- 全参数微调
- LoRA
- QLoRA

```python
print("Hello World!")
```

## 四、其他问题

- 微调是否有足够的数据？
- 微调大模型还是调整自己的提示模板？
    - 若能调整提示模板以提升效果，是最经济的方式
- 其他策略：RAG
